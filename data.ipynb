{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from scipy import sparse\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.decomposition import TruncatedSVD, LatentDirichletAllocation\n",
    "\n",
    "\n",
    "\n",
    "import  textblob\n",
    "from textblob import Word\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer, TfidfTransformer\n",
    "\n",
    "\n",
    "import re    #for regex\n",
    "\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "# Set the NLTK data path to the local directory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv('Womens Clothing Reviews Data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Performing Exploratory Analysis on the Data to Understand the Patterns:\n",
    " Exploratory analysis involves examining the dataset to get an initial understanding of its structure, variables, and potential patterns. This step is crucial for identifying trends, outliers, and relationships within the data. The goal is to gain insights into customer behaviors and preferences based on their demographics and reviews. Exploratory analysis may include data visualizations such as bar plots, histograms, scatter plots, and summary statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a. Characteristic of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 'head()' method is used to retrieve the top rows of the Dataframe. By defult, it returnd the five rows.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this line show about dataset, including datatypes, non-null counts, and memory usage.\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary statistics for numerical columns \n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check null data\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop null data\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check again if there's any other null data\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find data duplicate and drop duplicate data\n",
    "data.drop_duplicates() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move cleaned data to other file\n",
    "data.to_csv('cleaned data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Virtualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the cleaned data \n",
    "data = pd.read_csv('cleaned data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Exploratory Data Analysis (EDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x='Recommend Flag',data=data, palette='YlGnBu_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x='Rating',data=data, palette='YlGnBu_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x='Rating',hue='Category',data= data,palette='CMRmap')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x='Rating',hue='Subcategory1',data= data,palette='viridis')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x='Recommend Flag',hue='Subcategory1',data=data,palette='YlGnBu_r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.distplot(data['Customer Age'],color='darkred',bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Perform Text Mining Tasks to Understand the Most Frequent Words for Positive and Negative Sentiment. Create Word Clouds for the Positive & Negative Reviews Separately:\n",
    "\n",
    "Text mining involves analyzing and extracting information from text data. In this case, the objective is to analyze customer reviews submitted on the website. The first step is to process and clean the text data by removing stopwords, special characters, and converting the text to lowercase. Next, sentiment analysis can be performed to classify reviews as positive or negative. Word frequency analysis will help identify the most common words used in positive and negative reviews. Word clouds are visual representations of word frequencies, and separate word clouds can be created for positive and negative sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column called 'sentiment' containing the sentiment polarity score for each review text in the 'Review_Text' column. \n",
    "# This sentiment score reflects the overall sentiment of the text, whether it is positive, negative, or neutral.\n",
    "\n",
    "data['Review Text'] = data['Review Text'].astype(str)\n",
    "data['sentiment'] = data[\"Review Text\"].apply(lambda x: TextBlob(x).sentiment.polarity ) \n",
    "data.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data in to positive, negative and neutral sentiments and add a column sentiment_category\n",
    "data['sentiment_cat'] = np.where(data.sentiment>0.1,'Positive', np.where(data.sentiment<0.1, 'Negative', 'Nuetral'))\n",
    "#df['sentiment_cat'] = np.where(df.sentiment>0.1,'Positive', np.where(data.sentiment<-0.1,'Negative', 'Nuetral'))\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total positive, negative and neutral sentiments in sentiment_cat using .value_counts()\n",
    "data.sentiment_cat.value_counts()\n",
    "\n",
    "#df.sentiment_cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sentiment_cat.value_counts().plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('Sentiment_plot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Rating.value_counts()  #rating count \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data.sentiment_cat, data.Rating)\n",
    "#pd.crosstab(df.sentiment_cat, df.Rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Divide the data into three groups on the basis of sentiments like positive, negative and neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_neg = data[(data.sentiment_cat=='Negative')]\n",
    "data_pos = data[(data.sentiment_cat=='Positive')]\n",
    "data_neu = data[(data.sentiment_cat=='Neutral')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## X-variable is Review_text and y-variable is Rating\n",
    "# define X and y\n",
    "X = data['Review Text']\n",
    "y = data['Rating']\n",
    "\n",
    "# split the new DataFrame into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split the data into train & Test for positive sentiments and negative sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new DataFrame that only contains the 5 Rating and 1-Rating reviews\n",
    "#women_clothing = women_clothing[(women_clothing.Rating==5) | (women_clothing.Rating==1)]\n",
    "\n",
    "# define X and y\n",
    "X2 = data_pos['Review Text']\n",
    "y2 = data_pos['Rating']\n",
    "\n",
    "# split the new DataFrame into training and testing sets\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, random_state=1)\n",
    "print(X2_train.shape)\n",
    "print(X2_test.shape)\n",
    "print(y2_train.shape)\n",
    "print(y2_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X1 = data_neg['Review Text']\n",
    "y1 = data_neg['Rating']\n",
    "\n",
    "# split the new DataFrame into training and testing sets\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, random_state=1)\n",
    "print(X1_train.shape)\n",
    "print(X1_test.shape)\n",
    "print(y1_train.shape)\n",
    "print(y1_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pos.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_neg.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating user defined functions for clean the text and pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abbrevations and Words correction\n",
    "def clean_text(Review_Text):\n",
    "    Review_Text = Review_Text.lower()\n",
    "    Review_Text = Review_Text.strip()\n",
    "    Review_Text = re.sub(r' +', ' ', Review_Text)\n",
    "    Review_Text = re.sub(r\"[-()\\\"#/@;:{}`+=~|.!?*&£%€¦_><‘|,'0-9]\", \"\", Review_Text)\n",
    "    Review_Text = Review_Text.replace('wat', 'what').replace('txts', 'texts').replace('vry', 'very').replace('gud', 'good').replace('nyt', 'night').replace('msg', 'message')\n",
    "    return(Review_Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = list(set(nltk.corpus.stopwords.words('english')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = list(set(sw + ['the', 'me', 'how', 'what']))\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(Review_Text):\n",
    "    Review_Text = Review_Text.str.replace('/','')                           #Replacing the / with none\n",
    "    Review_Text = Review_Text.apply(lambda x: \" \".join(x for x in x.split() if x not in stop)) #Removing stop words\n",
    "    Review_Text = Review_Text.apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))   #lemmatization\n",
    "    return(Review_Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(lambda x: clean_text(x))\n",
    "X_test = X_test.apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pre_process(X_train)\n",
    "X_test=pre_process(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CLean the text and pre-process the data for positive sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train = X2_train.apply(lambda x: clean_text(x))\n",
    "X2_test = X2_test.apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train=pre_process(X2_train)\n",
    "X2_test=pre_process(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CLean the text and pre-process the data for negative sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train = X1_train.apply(lambda x: clean_text(x))\n",
    "X1_test = X1_test.apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train=pre_process(X1_train)\n",
    "X1_test=pre_process(X1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vectorization (Count, Tfidf) for positive sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "count_vect2 = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}', \n",
    "                             ngram_range=(1, 1 ), \n",
    "                             min_df=5, \n",
    "                             encoding='latin-1' ,\n",
    "                             max_features=800)\n",
    "xtrain2_count = count_vect2.fit_transform(X2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain2_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vectorization (Count, Tfidf) for negative sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect1 = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}', \n",
    "                             ngram_range=(1, 1 ), \n",
    "                             min_df=5, \n",
    "                             encoding='latin-1' ,\n",
    "                             max_features=800)\n",
    "xtrain1_count = count_vect1.fit_transform(X1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### View the document term metrics for positive sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm=xtrain2_count.toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_vect2.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm1=pd.DataFrame(dtm, columns = count_vect2.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm1.apply(sum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### View the document term metrics for negative sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm4=xtrain1_count.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_vect1.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm5=pd.DataFrame(dtm4, columns = count_vect1.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm5.apply(sum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word frequencies for positive sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = pd.DataFrame(dtm1.apply(sum).head(40), columns=['freq'])\n",
    "word_freq.sort_values('freq', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq_dictionary = dict(dtm1.apply(sum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq.plot(kind='bar', color='Green')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word frequencies for negative sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word_freq1 = pd.DataFrame(dtm5.apply(sum).head(40), columns=['freq'])\n",
    "word_freq1.sort_values('freq', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq_dictionary1 = dict(dtm5.apply(sum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq_dictionary1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For making word_clouds for postive sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud ,STOPWORDS\n",
    "wordcloud = WordCloud(background_color='white', stopwords=stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = wordcloud.generate_from_frequencies(word_freq_dictionary)\n",
    "\n",
    "fig = plt.figure(1, figsize=(12, 12))\n",
    "plt.axis('off')\n",
    "plt.imshow(wordcloud)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('positive_wordcloud')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For making word_clouds for negative sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud ,STOPWORDS\n",
    "wordcloud1 = WordCloud(background_color='white', stopwords=stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = wordcloud1.generate_from_frequencies(word_freq_dictionary1)\n",
    "\n",
    "fig = plt.figure(1, figsize=(12, 12))\n",
    "plt.axis('off')\n",
    "plt.imshow(wordcloud1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('Negative_wordcloud')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Understand sentiment among the customers on the different categories, sub categories,products by location and age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age group'] = pd.cut(x= data['Customer Age'],bins=[20, 29, 39, 49,59 ,69,79,89 ,99])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['Location', 'age group','Category','Subcategory1','SubCategory2',\"sentiment_cat\" ]).agg({'sentiment_cat': 'count'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.Perform predictive analytics to understand the drivers of customers who are recommending the products.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4 = data['Review Text']\n",
    "y4 = data['Recommend Flag']\n",
    "\n",
    "# split the new DataFrame into training and testing sets\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, random_state=1)\n",
    "print(X4_train.shape)\n",
    "print(X4_test.shape)\n",
    "print(y4_train.shape)\n",
    "print(y4_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4_train = X4_train.apply(lambda x: clean_text(x))\n",
    "X4_test = X4_test.apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "count_vect = CountVectorizer(analyzer='word', \n",
    "                             token_pattern=r'\\w{1,}', \n",
    "                             ngram_range=(1, 1 ), \n",
    "                             min_df=5, \n",
    "                             lowercase = True,\n",
    "                             encoding='latin-1' , \n",
    "                             max_features=100)\n",
    "X_train_count4 = count_vect.fit_transform(X4_train)\n",
    "feature_names_count = count_vect.get_feature_names_out()\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', \n",
    "                             token_pattern=r'\\w{1,}', \n",
    "                             ngram_range=(1, 1 ), \n",
    "                             min_df=5, \n",
    "                             encoding='latin-1' , \n",
    "                             lowercase = True,\n",
    "                             max_features=100)\n",
    "X_train_tfidf4 = tfidf_vect.fit_transform(X4_train)\n",
    "feature_names_tfidf = tfidf_vect.get_feature_names_out()\n",
    "\n",
    "#Test\n",
    "X_test_count4 = count_vect.transform(X4_test)\n",
    "X_test_tfidf4 = tfidf_vect.transform(X4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_count=pd.DataFrame(X_train_count4.toarray(), columns=count_vect.get_feature_names_out())\n",
    "dtm_tfidf=pd.DataFrame(X_train_tfidf4.toarray(), columns=tfidf_vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummies(df, colname):\n",
    "    col_dummies = pd.get_dummies(df[colname], prefix = colname, drop_first = True)\n",
    "    df = pd.concat([df, col_dummies], axis = 1)\n",
    "    df.drop(colname, axis = 1, inplace = True )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = data[['Category', 'Subcategory1', 'SubCategory2', 'sentiment_cat','Location', 'Channel']]\n",
    "\n",
    "# for c_feature in categorical_features\n",
    "for c_feature in ['Category', 'Subcategory1', 'SubCategory2', 'sentiment_cat','Location', 'Channel']:\n",
    "    cat_vars[c_feature] = cat_vars[c_feature].astype('category')\n",
    "    cat_vars = create_dummies(cat_vars, c_feature)\n",
    " \n",
    "\n",
    "cat_vars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =data.loc[:, [ 'Review Text', 'Customer Age', 'Rating', 'sentiment','Recommend Flag']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([ data,cat_vars], axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X and y\n",
    "feature_cols = [ 'Review Text', 'Customer Age', 'Rating', 'sentiment','Recommend Flag',\n",
    "                'Category_General Petite', 'Category_Initmates','Subcategory1_Dresses', 'Subcategory1_Intimate',\n",
    "                'Subcategory1_Jackets','Subcategory1_Tops', 'Subcategory1_Trend',\n",
    "       'SubCategory2_Casual bottoms', 'SubCategory2_Chemises',\n",
    "       'SubCategory2_Dresses', 'SubCategory2_Fine gauge',\n",
    "       'SubCategory2_Intimates', 'SubCategory2_Jackets', 'SubCategory2_Jeans',\n",
    "       'SubCategory2_Knits', 'SubCategory2_Layering', 'SubCategory2_Legwear',\n",
    "       'SubCategory2_Lounge', 'SubCategory2_Outerwear', 'SubCategory2_Pants',\n",
    "       'SubCategory2_Shorts', 'SubCategory2_Skirts', 'SubCategory2_Sleep',\n",
    "       'SubCategory2_Sweaters', 'SubCategory2_Swim', 'SubCategory2_Trend',\n",
    "       'sentiment_cat_Nuetral', 'sentiment_cat_Positive', 'Location_Chennai',\n",
    "       'Location_Gurgaon', 'Location_Mumbai', 'Channel_Web']\n",
    "X = data[feature_cols]\n",
    "y = data['Recommend Flag']\n",
    "\n",
    "#split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Review Text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use  TfidfVectorizer with Review_Text column only\n",
    "vect = TfidfVectorizer(lowercase=True, stop_words='english', max_features=100, min_df=5, ngram_range=(1, 2))\n",
    "X_train_dtm = vect.fit_transform(X_train['Review Text'])\n",
    "X_test_dtm = vect.transform(X_test['Review Text'])\n",
    "print(X_train_dtm.shape)\n",
    "print(X_test_dtm.shape)\n",
    "\n",
    "# shape of other four feature columns\n",
    "X_train.drop('Review Text', axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vect.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use  TfidfVectorizer with Review_Text column only\n",
    "vect = TfidfVectorizer(lowercase=True, stop_words='english', max_features=100, min_df=5, ngram_range=(1, 2))\n",
    "X_train_dtm = vect.fit_transform(X_train['Review Text'])\n",
    "X_test_dtm = vect.transform(X_test['Review Text'])\n",
    "print(X_train_dtm.shape)\n",
    "print(X_test_dtm.shape)\n",
    "\n",
    "# shape of other four feature columns\n",
    "X_train.drop('Review Text', axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vect.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast other feature columns to float and convert to a sparse matrix\n",
    "extra = sparse.csr_matrix(X_train.drop('Review Text', axis=1).astype(float))\n",
    "extra.shape\n",
    "\n",
    "# combine sparse matrices\n",
    "X_train_dtm_extra = sparse.hstack((X_train_dtm, extra))\n",
    "X_train_dtm_extra.shape\n",
    "\n",
    "# repeat for testing set\n",
    "extra = sparse.csr_matrix(X_test.drop('Review Text', axis=1).astype(float))\n",
    "X_test_dtm_extra = sparse.hstack((X_test_dtm, extra))\n",
    "X_test_dtm_extra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use logistic regression with text column only\n",
    "logreg = LogisticRegression(C=1e9)\n",
    "logreg.fit(X_train_dtm, y_train)\n",
    "y_pred_class = logreg.predict(X_test_dtm)\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(logreg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the score for validation\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "\n",
    "tr_pred=logreg.predict(X_train_dtm)\n",
    "y_pred = logreg.predict(X_test_dtm)\n",
    "\n",
    "\n",
    "trprecision,trrecall,trfscore,trsupport=score(y_train,tr_pred)\n",
    "tracc=accuracy_score(y_train,tr_pred)\n",
    "precision,recall,fscore,support=score(y_test,y_pred)\n",
    "acc=accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Training\n",
    "\n",
    "print('Precision : ',trprecision)\n",
    "print('\\nRecall : ',trrecall)\n",
    "print('\\nF-Score :',trfscore)\n",
    "print('\\nAccuracy : ',tracc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision : ',precision)\n",
    "print('\\nRecall : ',recall)\n",
    "print('\\nF-Score :',fscore)\n",
    "print('\\nAccuracy : ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use logistic regression with all features\n",
    "#logreg1 = LogisticRegression(C=1e9)\n",
    "#logreg1.fit(X_train_dtm_extra, y_train)\n",
    "#y_pred_class = logreg.predict(X_test_dtm_extra)\n",
    "#print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "#Saving model\n",
    "import pickle\n",
    "Pkl_Filename = \"Pickle_LR_Model.pkl\"  \n",
    "\n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(logreg, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Load the Model back from file\n",
    "with open(Pkl_Filename, 'rb') as file:  \n",
    "    Pickled_LR_Model = pickle.load(file)\n",
    "\n",
    "Pickled_LR_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Reloaded Model to \n",
    "# Calculate the accuracy score and predict target values\n",
    "\n",
    "# Calculate the Score \n",
    "score = Pickled_LR_Model.score(X_test_dtm, y_test)  \n",
    "# Print the Score\n",
    "print(\"Test score: {0:.2f} %\".format(100 * score))  \n",
    "\n",
    "# Predict the Labels using the reloaded Model\n",
    "Ypredict = Pickled_LR_Model.predict(X_test_dtm)  \n",
    "Ypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vect.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X and y\n",
    "feature_cols = [ 'Review Text', 'Customer Age', 'sentiment','Recommend Flag',\n",
    "                'Category_General Petite', 'Category_Initmates','Subcategory1_Dresses', 'Subcategory1_Intimate',\n",
    "                'Subcategory1_Jackets','Subcategory1_Tops', 'Subcategory1_Trend',\n",
    "       'SubCategory2_Casual bottoms', 'SubCategory2_Chemises',\n",
    "       'SubCategory2_Dresses', 'SubCategory2_Fine gauge',\n",
    "       'SubCategory2_Intimates', 'SubCategory2_Jackets', 'SubCategory2_Jeans',\n",
    "       'SubCategory2_Knits', 'SubCategory2_Layering', 'SubCategory2_Legwear',\n",
    "       'SubCategory2_Lounge', 'SubCategory2_Outerwear', 'SubCategory2_Pants',\n",
    "       'SubCategory2_Shorts', 'SubCategory2_Skirts', 'SubCategory2_Sleep',\n",
    "       'SubCategory2_Sweaters', 'SubCategory2_Swim', 'SubCategory2_Trend',\n",
    "       'sentiment_cat_Nuetral', 'sentiment_cat_Positive', 'Location_Chennai',\n",
    "       'Location_Gurgaon', 'Location_Mumbai', 'Channel_Web']\n",
    "X = data[feature_cols]\n",
    "y = data['Rating']\n",
    "\n",
    "#split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use  TfidfVectorizer with Review_Text column only\n",
    "vect = TfidfVectorizer(lowercase=True, stop_words='english', max_features=100, min_df=5, ngram_range=(1, 2))\n",
    "X_train_dtm = vect.fit_transform(X_train['Review Text'])\n",
    "X_test_dtm = vect.transform(X_test['Review Text'])\n",
    "print(X_train_dtm.shape)\n",
    "print(X_test_dtm.shape)\n",
    "\n",
    "# shape of other four feature columns\n",
    "X_train.drop('Review Text', axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vect.get_feature_names_out())\n",
    "# use logistic regression with text column only\n",
    "logreg2 = LogisticRegression(C=1e9)\n",
    "logreg2.fit(X_train_dtm, y_train)\n",
    "y_pred_class = logreg2.predict(X_test_dtm)\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using KNN model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model3=KNeighborsClassifier(n_neighbors=5,n_jobs=-1)\n",
    "model3.fit(X_train_dtm,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Finding the score for validation\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "\n",
    "tr_pred=logreg2.predict(X_train_dtm)\n",
    "y_pred = logreg2.predict(X_test_dtm)\n",
    "\n",
    "\n",
    "trprecision,trrecall,trfscore,trsupport=score(y_train,tr_pred)\n",
    "tracc=accuracy_score(y_train,tr_pred)\n",
    "precision,recall,fscore,support=score(y_test,y_pred)\n",
    "acc=accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Training\n",
    "\n",
    "print('Precision : ',trprecision)\n",
    "print('\\nRecall : ',trrecall)\n",
    "print('\\nF-Score :',trfscore)\n",
    "print('\\nAccuracy : ',tracc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Testing\n",
    "\n",
    "print('Precision : ',precision)\n",
    "print('\\nRecall : ',recall)\n",
    "print('\\nF-Score :',fscore)\n",
    "print('\\nAccuracy : ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid,  valid_y, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes (With only review_text in X-vribles)\n",
    "# Naive Bayes on Count Vectors and TF-IDF\n",
    "\n",
    "\n",
    "accuracy_L1 = train_model(naive_bayes.MultinomialNB(), X_train_dtm, y_train, X_test_dtm, y_test)\n",
    "print(\"NB  for L1, TFIDF Vectors: \", accuracy_L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "# Logistic Regression on Count Vectors and TF-IDF\n",
    "accuracy_L1 = train_model(LogisticRegression(), X_train_dtm, y_train, X_test_dtm, y_test)\n",
    "print(\"LR  for L1, tfidf Vectors: \", accuracy_L1)\n",
    "\n",
    "# Logistic Regression on Word Level TF IDF Vectors\n",
    "#accuracy_L1 = train_model(LogisticRegression(), X_train_count, y_train, X_test_count, y_test)\n",
    "#print(\"LR  for L1, WordLevel count: \", accuracy_L1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear SVC\n",
    "# Linear SVC on Count Vectors and TF-IDF\n",
    "\n",
    "\n",
    "accuracy_L1 = train_model(svm.LinearSVC(), X_train_dtm, y_train, X_test_dtm, y_test)\n",
    "print(\"SVC  for L1, Count Vectors: \", accuracy_L1)\n",
    "\n",
    "# Linear SVC on Word Level TF IDF Vectors\n",
    "#accuracy_L1 = train_model(svm.LinearSVC(), X_train_count, y_train, X_test_count, y_test)\n",
    "#print(\"SVC  for L1, WordLevel TF-IDF: \", accuracy_L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vect.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e. Create topics and understand themes behind the topics by performing Topic Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Topic Modeling using gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Gensim\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "X_train_tokens = [doc.split() for doc in X_train]  \n",
    "X_train_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(X_train_tokens)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in X_train_tokens]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=5, id2word = dictionary,passes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=5, id2word = dictionary,passes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ldamodel.show_topics(formatted=False, num_words=30)\n",
    "    \n",
    "for t in range(len(topics)):\n",
    "    print(\"\\nTopic {}, top {} words:\".format(t+1,30))\n",
    "    print(\" \".join([w[0] for w in topics[t][1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Topic Modeling using sklearn.decomposition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a LDA Model\n",
    "from sklearn import decomposition\n",
    "\n",
    "\n",
    "lda_model = decomposition.LatentDirichletAllocation(n_components=10, learning_method='online', max_iter=20)\n",
    "X_topics = lda_model.fit_transform(X_train_dtm)\n",
    "topic_word = lda_model.components_ \n",
    "vocab = count_vect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the topic models\n",
    "n_top_words = 40\n",
    "topic_summaries = []\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    topic_summaries.append(' '.join(topic_words))\n",
    "\n",
    "topic_summaries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
